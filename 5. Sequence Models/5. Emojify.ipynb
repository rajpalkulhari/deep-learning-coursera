{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emojify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/emojify_data.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183,)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work is horrible 😞\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  is converted to  [0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 30\n",
    "print(Y_train[index], \" is converted to \", Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing Emojifier-V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of word  cucumber  is  113317\n",
      "index at  121233  has word  deport\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 121233\n",
    "print(\"the index of word \", word, \" is \",word_to_index[word])\n",
    "print(\"index at \", index, \" has word \",index_to_word[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    words = sentence.lower().split()\n",
    "    \n",
    "    out_vac = np.zeros((50,))\n",
    "    \n",
    "    for w in words:\n",
    "        out_vac += word_to_vec_map[w]\n",
    "    \n",
    "    out_vac = out_vac/len(words)\n",
    "    \n",
    "    return out_vac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg =  [-0.008005    0.56370833 -0.50427333  0.258865    0.55131103  0.03104983\n",
      " -0.21013718  0.16893933 -0.09590267  0.141784   -0.15708967  0.18525867\n",
      "  0.6495785   0.38371117  0.21102167  0.11301667  0.02613967  0.26037767\n",
      "  0.05820667 -0.01578167 -0.12078833 -0.02471267  0.4128455   0.5152061\n",
      "  0.38756167 -0.898661   -0.535145    0.33501167  0.68806933 -0.2156265\n",
      "  1.797155    0.10476933 -0.36775333  0.750785    0.10282583  0.348925\n",
      " -0.27262833  0.66768    -0.10706167 -0.283635    0.59580117  0.28747333\n",
      " -0.3366635   0.23393817  0.34349183  0.178405    0.1166155  -0.076433\n",
      "  0.1445417   0.09808667]\n"
     ]
    }
   ],
   "source": [
    "avg = sentence_to_avg(\"Morrocan couscous is my favorite dish\", word_to_vec_map)\n",
    "print(\"avg = \", avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    np.random.seed(1)\n",
    "    m = Y.shape[0]\n",
    "    n_y = 5       \n",
    "    n_h = 50  # dimensions of the GloVe vectors    \n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    Y_oh = convert_to_one_hot(Y, C = n_y) \n",
    "    for t in range(num_iterations):                       # Loop over the number of iterations\n",
    "        for i in range(m):                                # Loop over the training examples\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "            z = np.dot(W, avg) + b\n",
    "            a = softmax(z)\n",
    "            cost = - np.sum(Y_oh[i] * np.log(a))\n",
    "            \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map)\n",
    "\n",
    "    return pred, W, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(183,)\n",
      "(183,)\n",
      "(183, 5)\n",
      "French macaroon is so tasty\n",
      "<class 'numpy.ndarray'>\n",
      "(20,)\n",
      "(20,)\n",
      "(183, 5)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(X_train[0])\n",
    "print(type(X_train))\n",
    "Y = np.asarray([5,0,0,5, 4, 4, 4, 6, 6, 4, 1, 1, 5, 6, 6, 3, 6, 3, 4, 4])\n",
    "print(Y.shape)\n",
    "\n",
    "X = np.asarray(['I am going to the bar tonight', 'I love you', 'miss you my dear',\n",
    " 'Lets go party and drinks','Congrats on the new job','Congratulations',\n",
    " 'I am so happy for you', 'Why are you feeling bad', 'What is wrong with you',\n",
    " 'You totally deserve this prize', 'Let us go play football',\n",
    " 'Are you down for football this afternoon', 'Work hard play harder',\n",
    " 'It is suprising how people can be dumb sometimes',\n",
    " 'I am very disappointed','It is the best day in my life',\n",
    " 'I think I will end up alone','My life is so boring','Good job',\n",
    " 'Great so awesome'])\n",
    "\n",
    "print(X.shape)\n",
    "print(np.eye(5)[Y_train.reshape(-1)].shape)\n",
    "print(type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.2274145089650235\n",
      "Accuracy: 0.34972677595628415\n",
      "Epoch: 100 --- cost = 0.6550137321234394\n",
      "Accuracy: 0.8579234972677595\n",
      "Epoch: 200 --- cost = 0.4983037388238118\n",
      "Accuracy: 0.9016393442622951\n",
      "Epoch: 300 --- cost = 0.4105004435246948\n",
      "Accuracy: 0.9180327868852459\n",
      "[[4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, Y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9289617486338798\n",
      "Test set:\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, Y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, Y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n",
      "\n",
      "i adore you 😄\n",
      "i love you ❤️\n",
      "funny lol 😄\n",
      "lets play with a ball ⚾\n",
      "food is ready 🍴\n",
      "not feeling happy 😄\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, word_to_vec_map)\n",
    "print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ❤️    ⚾    😄    😞   🍴\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    1    0    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            4    0   14    0    0   18\n",
      "3            0    0    1   15    0   16\n",
      "4            0    0    0    1    6    7\n",
      "All         10    8   16   16    6   56\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Emojifier-V2: Using LSTMs in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0] # number of training examples\n",
    "    \n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m): # loop over training examples\n",
    "        sentence_words = X[i].lower().split()\n",
    "        j = 0\n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j = j + 1\n",
    "                \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n",
      "X1_indices = [[155345. 225122.      0.      0.      0.]\n",
      " [220930. 286375.  69714.      0.      0.]\n",
      " [151204. 192973. 302254. 151349. 394475.]]\n"
     ]
    }
   ],
   "source": [
    "X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n",
    "X1_indices = sentences_to_indices(X1,word_to_index, max_len = 5)\n",
    "print(\"X1 =\", X1)\n",
    "print(\"X1_indices =\", X1_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    vocab_len = len(word_to_index) + 1                  \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      \n",
    "    \n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    for word, index in word_to_index.items():\n",
    "        emb_matrix[index, :] = word_to_vec_map[word]\n",
    "\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim,trainable=False)\n",
    "\n",
    "    embedding_layer.build((None,))\n",
    "    \n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights[0][1][3] = -0.3403\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
    "    sentence_indices = Input(shape=input_shape, dtype=np.int32)\n",
    "    embedding_layer =  pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)   \n",
    "    X = LSTM(128, return_sequences=True)(embeddings)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = LSTM(128)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(5, activation='softmax')(X)\n",
    "    X =  Activation('softmax')(X)\n",
    "    \n",
    "    model = Model(sentence_indices, X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "183/183 [==============================] - 1s 8ms/step - loss: 1.6019 - acc: 0.2459\n",
      "Epoch 2/50\n",
      "183/183 [==============================] - 0s 743us/step - loss: 1.5626 - acc: 0.3115\n",
      "Epoch 3/50\n",
      "183/183 [==============================] - 0s 738us/step - loss: 1.5412 - acc: 0.3552\n",
      "Epoch 4/50\n",
      "183/183 [==============================] - 0s 781us/step - loss: 1.5312 - acc: 0.3607\n",
      "Epoch 5/50\n",
      "183/183 [==============================] - 0s 738us/step - loss: 1.5030 - acc: 0.3989\n",
      "Epoch 6/50\n",
      "183/183 [==============================] - 0s 989us/step - loss: 1.4897 - acc: 0.3934\n",
      "Epoch 7/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.4423 - acc: 0.4590\n",
      "Epoch 8/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.3786 - acc: 0.5519\n",
      "Epoch 9/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.3376 - acc: 0.5847\n",
      "Epoch 10/50\n",
      "183/183 [==============================] - 0s 902us/step - loss: 1.3452 - acc: 0.5519\n",
      "Epoch 11/50\n",
      "183/183 [==============================] - 0s 924us/step - loss: 1.3238 - acc: 0.6066\n",
      "Epoch 12/50\n",
      "183/183 [==============================] - 0s 831us/step - loss: 1.2363 - acc: 0.7268\n",
      "Epoch 13/50\n",
      "183/183 [==============================] - 0s 781us/step - loss: 1.1957 - acc: 0.7486\n",
      "Epoch 14/50\n",
      "183/183 [==============================] - 0s 776us/step - loss: 1.1583 - acc: 0.7760\n",
      "Epoch 15/50\n",
      "183/183 [==============================] - 0s 749us/step - loss: 1.1061 - acc: 0.8142\n",
      "Epoch 16/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.1060 - acc: 0.8033\n",
      "Epoch 17/50\n",
      "183/183 [==============================] - 0s 956us/step - loss: 1.1367 - acc: 0.7760\n",
      "Epoch 18/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.0973 - acc: 0.8197\n",
      "Epoch 19/50\n",
      "183/183 [==============================] - 0s 896us/step - loss: 1.1378 - acc: 0.7705\n",
      "Epoch 20/50\n",
      "183/183 [==============================] - 0s 792us/step - loss: 1.0433 - acc: 0.8689\n",
      "Epoch 21/50\n",
      "183/183 [==============================] - 0s 852us/step - loss: 1.0710 - acc: 0.8251\n",
      "Epoch 22/50\n",
      "183/183 [==============================] - 0s 896us/step - loss: 1.0686 - acc: 0.8306\n",
      "Epoch 23/50\n",
      "183/183 [==============================] - 0s 995us/step - loss: 1.0468 - acc: 0.8579\n",
      "Epoch 24/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.0221 - acc: 0.8907\n",
      "Epoch 25/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.0210 - acc: 0.8852\n",
      "Epoch 26/50\n",
      "183/183 [==============================] - 0s 836us/step - loss: 1.0075 - acc: 0.9016\n",
      "Epoch 27/50\n",
      "183/183 [==============================] - 0s 945us/step - loss: 1.0038 - acc: 0.8962\n",
      "Epoch 28/50\n",
      "183/183 [==============================] - 0s 852us/step - loss: 1.0375 - acc: 0.8743\n",
      "Epoch 29/50\n",
      "183/183 [==============================] - 0s 814us/step - loss: 1.0208 - acc: 0.8852\n",
      "Epoch 30/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.0187 - acc: 0.8852\n",
      "Epoch 31/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.9858 - acc: 0.9235\n",
      "Epoch 32/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 1.0050 - acc: 0.8962\n",
      "Epoch 33/50\n",
      "183/183 [==============================] - 0s 792us/step - loss: 0.9858 - acc: 0.9235\n",
      "Epoch 34/50\n",
      "183/183 [==============================] - 0s 842us/step - loss: 1.0047 - acc: 0.9071\n",
      "Epoch 35/50\n",
      "183/183 [==============================] - 0s 710us/step - loss: 0.9886 - acc: 0.9126\n",
      "Epoch 36/50\n",
      "183/183 [==============================] - 0s 754us/step - loss: 0.9969 - acc: 0.9016\n",
      "Epoch 37/50\n",
      "183/183 [==============================] - 0s 754us/step - loss: 0.9935 - acc: 0.9126\n",
      "Epoch 38/50\n",
      "183/183 [==============================] - 0s 743us/step - loss: 0.9777 - acc: 0.9344\n",
      "Epoch 39/50\n",
      "183/183 [==============================] - 0s 743us/step - loss: 0.9844 - acc: 0.9235\n",
      "Epoch 40/50\n",
      "183/183 [==============================] - 0s 699us/step - loss: 0.9849 - acc: 0.9344\n",
      "Epoch 41/50\n",
      "183/183 [==============================] - 0s 661us/step - loss: 0.9589 - acc: 0.9508\n",
      "Epoch 42/50\n",
      "183/183 [==============================] - 0s 836us/step - loss: 0.9654 - acc: 0.9454\n",
      "Epoch 43/50\n",
      "183/183 [==============================] - 0s 743us/step - loss: 0.9852 - acc: 0.9235\n",
      "Epoch 44/50\n",
      "183/183 [==============================] - 0s 869us/step - loss: 1.0062 - acc: 0.8962\n",
      "Epoch 45/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.9687 - acc: 0.9399\n",
      "Epoch 46/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.9571 - acc: 0.9508\n",
      "Epoch 47/50\n",
      "183/183 [==============================] - 0s 995us/step - loss: 0.9572 - acc: 0.9508\n",
      "Epoch 48/50\n",
      "183/183 [==============================] - 0s 1ms/step - loss: 0.9665 - acc: 0.9399\n",
      "Epoch 49/50\n",
      "183/183 [==============================] - 0s 831us/step - loss: 0.9783 - acc: 0.9235\n",
      "Epoch 50/50\n",
      "183/183 [==============================] - 0s 792us/step - loss: 0.9664 - acc: 0.9399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac39120710>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 317us/step\n",
      "\n",
      "Test accuracy =  0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len = maxLen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print(\"\\nTest accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:😄 prediction: he got a very nice raise\t❤️\n",
      "Expected emoji:😄 prediction: she got me a nice present\t❤️\n",
      "Expected emoji:😄 prediction: he is a good friend\t❤️\n",
      "Expected emoji:😞 prediction: work is hard\t😄\n",
      "Expected emoji:⚾ prediction: enjoy your game😄\n",
      "Expected emoji:😄 prediction: will you be my valentine\t❤️\n",
      "Expected emoji:❤️ prediction: I like your jacket \t😄\n",
      "Expected emoji:🍴 prediction: I did not have breakfast 😞\n"
     ]
    }
   ],
   "source": [
    "C = 5\n",
    "y_test_oh = np.eye(C)[Y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != Y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(Y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feeling happy today 😄\n",
      "not feeling happy today 😞\n"
     ]
    }
   ],
   "source": [
    "x_test = np.array(['feeling happy today','not feeling happy today'])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(x_test)):\n",
    "    num = np.argmax(pred[i])\n",
    "    print(x_test[i] +' '+  label_to_emoji(num))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
