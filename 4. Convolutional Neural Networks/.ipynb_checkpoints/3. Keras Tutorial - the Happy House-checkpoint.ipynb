{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tutorail - the Happy House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from kt_utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 600\n",
      "number of test examples = 150\n",
      "X_train shape: (600, 64, 64, 3)\n",
      "Y_train shape: (600, 1)\n",
      "X_test shape: (150, 64, 64, 3)\n",
      "Y_test shape: (150, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "Y_train = Y_train_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def happy_model(input_shape):\n",
    "    x_input = Input(input_shape)\n",
    "    \n",
    "    X = ZeroPadding2D((3,3))(x_input)\n",
    "    \n",
    "    X = Conv2D(32, (7,7), strides=(1, 1),name = \"conv0\")(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool')(X)\n",
    "    \n",
    "    X = Conv2D(32, (7,7), strides=(1, 1),name = \"conv1\")(X)\n",
    "    X = BatchNormalization(axis=3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1, activation='sigmoid', name='fc')(X)\n",
    "    \n",
    "    model = Model(inputs=x_input,outputs=X,name=\"HappyModel\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyModel = happy_model(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyModel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 2.1654 - acc: 0.5800\n",
      "Epoch 2/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.3109 - acc: 0.8633\n",
      "Epoch 3/50\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.1622 - acc: 0.9433\n",
      "Epoch 4/50\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.1449 - acc: 0.9433\n",
      "Epoch 5/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.1072 - acc: 0.9683\n",
      "Epoch 6/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.1009 - acc: 0.9667\n",
      "Epoch 7/50\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.1197 - acc: 0.9583\n",
      "Epoch 8/50\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0989 - acc: 0.9617\n",
      "Epoch 9/50\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.1047 - acc: 0.9633\n",
      "Epoch 10/50\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0900 - acc: 0.9717\n",
      "Epoch 11/50\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0884 - acc: 0.9683\n",
      "Epoch 12/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0769 - acc: 0.9750\n",
      "Epoch 13/50\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0519 - acc: 0.9783\n",
      "Epoch 14/50\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0418 - acc: 0.9833\n",
      "Epoch 15/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0551 - acc: 0.9817\n",
      "Epoch 16/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0641 - acc: 0.9833\n",
      "Epoch 17/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0566 - acc: 0.9783\n",
      "Epoch 18/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0297 - acc: 0.9900\n",
      "Epoch 19/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0678 - acc: 0.9783\n",
      "Epoch 20/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0604 - acc: 0.9783\n",
      "Epoch 21/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0492 - acc: 0.9817\n",
      "Epoch 22/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0545 - acc: 0.9817\n",
      "Epoch 23/50\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0635 - acc: 0.9683\n",
      "Epoch 24/50\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0465 - acc: 0.9917\n",
      "Epoch 25/50\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0370 - acc: 0.9917\n",
      "Epoch 26/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0239 - acc: 0.9933\n",
      "Epoch 27/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0268 - acc: 0.9933\n",
      "Epoch 28/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0294 - acc: 0.9933\n",
      "Epoch 29/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 30/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0186 - acc: 0.9967\n",
      "Epoch 31/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0408 - acc: 0.9817\n",
      "Epoch 32/50\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0156 - acc: 0.9950\n",
      "Epoch 33/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0263 - acc: 0.9883\n",
      "Epoch 34/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0764 - acc: 0.9733\n",
      "Epoch 35/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0571 - acc: 0.9717\n",
      "Epoch 36/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0243 - acc: 0.9867\n",
      "Epoch 37/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0263 - acc: 0.9933\n",
      "Epoch 38/50\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0262 - acc: 0.9900\n",
      "Epoch 39/50\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0243 - acc: 0.9950\n",
      "Epoch 40/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 41/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0087 - acc: 0.9983\n",
      "Epoch 42/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0158 - acc: 0.9933\n",
      "Epoch 43/50\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0553 - acc: 0.9817\n",
      "Epoch 44/50\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.1008 - acc: 0.9700\n",
      "Epoch 45/50\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0167 - acc: 0.9933\n",
      "Epoch 46/50\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0424 - acc: 0.9867\n",
      "Epoch 47/50\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0267 - acc: 0.9867\n",
      "Epoch 48/50\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0584 - acc: 0.9750\n",
      "Epoch 49/50\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0722 - acc: 0.9733\n",
      "Epoch 50/50\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0322 - acc: 0.9850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b937af05f8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happyModel.fit(x=X_train,y=Y_train,batch_size=32,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 3s 21ms/step\n",
      "Loss =  1.368675799369812\n",
      "Test accuracy =  0.673333334128062\n"
     ]
    }
   ],
   "source": [
    "preds = happyModel.evaluate(X_test,Y_test,batch_size=32,verbose=1,sample_weight=None)\n",
    "\n",
    "print(\"Loss = \",str(preds[0]))\n",
    "print(\"Test accuracy = \",str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 70, 70, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv2D)               (None, 64, 64, 32)        4736      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pool (MaxPooling2D)      (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 1)                 32769     \n",
      "=================================================================\n",
      "Total params: 37,633\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "happyModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(happyModel, to_file='HappyModel.png')\n",
    "SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
